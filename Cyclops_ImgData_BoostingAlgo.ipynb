{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cyclops ImgData_BoostingAlgo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhav48/Catboost-vs-Lightboost-vs-XGBoost-vs-Snapboost/blob/master/Cyclops_ImgData_BoostingAlgo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZn4G7yHo7O0",
        "colab_type": "text"
      },
      "source": [
        "# **Performance of Gradient Boosting Algorithms on a Image Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHvUaQFppB6k",
        "colab_type": "text"
      },
      "source": [
        "# This Notebook contains the comparative analysis of 3 Boosting Algorithms -\n",
        "XGBoost, SnapBoost and LightGBM trained and tested on a Image Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-paFoG9muPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost\n",
        "!pip install lightgbm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0MYZzRwkvX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "import catboost as ctb\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score    \n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "import matplotlib as mp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL5KOXASlgkm",
        "colab_type": "text"
      },
      "source": [
        "# **Loading the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV1vjIOblevf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "\"\"\"\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 \n",
        "training images and 10000 test images.\n",
        "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains \n",
        "exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random \n",
        "order, but some training batches may contain more images from one class than another. Between them, the training \n",
        "batches contain exactly 5000 images from each class.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def unpickle(file):\n",
        "    \"\"\"load the cifar-10 data\"\"\"\n",
        "\n",
        "    with open(file, 'rb') as fo:\n",
        "        data = pickle.load(fo, encoding='bytes')\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_cifar_10_data(data_dir, negatives=False):\n",
        "    \"\"\"\n",
        "    Return train_data, train_filenames, train_labels, test_data, test_filenames, test_labels\n",
        "    \"\"\"\n",
        "\n",
        "    # get the meta_data_dict\n",
        "    # num_cases_per_batch: 1000\n",
        "    # label_names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    # num_vis: :3072\n",
        "\n",
        "    meta_data_dict = unpickle(data_dir + \"/batches.meta\")\n",
        "    cifar_label_names = meta_data_dict[b'label_names']\n",
        "    cifar_label_names = np.array(cifar_label_names)\n",
        "\n",
        "    # training data\n",
        "    cifar_train_data = None\n",
        "    cifar_train_filenames = []\n",
        "    cifar_train_labels = []\n",
        "\n",
        "    # cifar_train_data_dict\n",
        "    # 'batch_label': 'training batch 5 of 5'\n",
        "    # 'data': ndarray\n",
        "    # 'filenames': list\n",
        "    # 'labels': list\n",
        "\n",
        "    for i in range(1, 6):\n",
        "        cifar_train_data_dict = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
        "        if i == 1:\n",
        "            cifar_train_data = cifar_train_data_dict[b'data']\n",
        "        else:\n",
        "            cifar_train_data = np.vstack((cifar_train_data, cifar_train_data_dict[b'data']))\n",
        "        cifar_train_filenames += cifar_train_data_dict[b'filenames']\n",
        "        cifar_train_labels += cifar_train_data_dict[b'labels']\n",
        "\n",
        "    cifar_train_data = cifar_train_data.reshape((len(cifar_train_data), 3, 32, 32))\n",
        "    if negatives:\n",
        "        cifar_train_data = cifar_train_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
        "    else:\n",
        "        cifar_train_data = np.rollaxis(cifar_train_data, 1, 4)\n",
        "    cifar_train_filenames = np.array(cifar_train_filenames)\n",
        "    cifar_train_labels = np.array(cifar_train_labels)\n",
        "\n",
        "    # test data\n",
        "    # cifar_test_data_dict\n",
        "    # 'batch_label': 'testing batch 1 of 1'\n",
        "    # 'data': ndarray\n",
        "    # 'filenames': list\n",
        "    # 'labels': list\n",
        "\n",
        "    cifar_test_data_dict = unpickle(data_dir + \"/test_batch\")\n",
        "    cifar_test_data = cifar_test_data_dict[b'data']\n",
        "    cifar_test_filenames = cifar_test_data_dict[b'filenames']\n",
        "    cifar_test_labels = cifar_test_data_dict[b'labels']\n",
        "\n",
        "    cifar_test_data = cifar_test_data.reshape((len(cifar_test_data), 3, 32, 32))\n",
        "    if negatives:\n",
        "        cifar_test_data = cifar_test_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
        "    else:\n",
        "        cifar_test_data = np.rollaxis(cifar_test_data, 1, 4)\n",
        "    cifar_test_filenames = np.array(cifar_test_filenames)\n",
        "    cifar_test_labels = np.array(cifar_test_labels)\n",
        "\n",
        "    return cifar_train_data, cifar_train_filenames, cifar_train_labels, \\\n",
        "        cifar_test_data, cifar_test_filenames, cifar_test_labels, cifar_label_names\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"show it works\"\"\"\n",
        "\n",
        "    cifar_10_dir = 'cifar-10-batches-py'\n",
        "\n",
        "    train_data, train_filenames, train_labels, test_data, test_filenames, test_labels, label_names = \\\n",
        "        load_cifar_10_data(cifar_10_dir)\n",
        "\n",
        "    print(\"Train data: \", train_data.shape)\n",
        "    print(\"Train filenames: \", train_filenames.shape)\n",
        "    print(\"Train labels: \", train_labels.shape)\n",
        "    print(\"Test data: \", test_data.shape)\n",
        "    print(\"Test filenames: \", test_filenames.shape)\n",
        "    print(\"Test labels: \", test_labels.shape)\n",
        "    print(\"Label names: \", label_names.shape)\n",
        "\n",
        "    # Don't forget that the label_names and filesnames are in binary and need conversion if used.\n",
        "\n",
        "    # display some random training images in a 25x25 grid\n",
        "    num_plot = 5\n",
        "    f, ax = plt.subplots(num_plot, num_plot)\n",
        "    for m in range(num_plot):\n",
        "        for n in range(num_plot):\n",
        "            idx = np.random.randint(0, train_data.shape[0])\n",
        "            ax[m, n].imshow(train_data[idx])\n",
        "            ax[m, n].get_xaxis().set_visible(False)\n",
        "            ax[m, n].get_yaxis().set_visible(False)\n",
        "    f.subplots_adjust(hspace=0.1)\n",
        "    f.subplots_adjust(wspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lETAqMFrk8Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data: shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = load_cifar_10_data(cifar-10-data-py)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00s_6BgFotMC",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocess the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLD3Cekkk_rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # X_train is 50000 rows of 3x32x32 values --> reshaped in 50000 x 3072\n",
        "RESHAPED = 3072\n",
        "\n",
        "X_train = X_train.reshape(50000, RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gUMoIO_lG-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # normalize the datasets\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY0gdLv0qg-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "def multiclass_roc_auc_score(y_test, pred, average=\"macro\"):\n",
        "    lb = preprocessing.LabelBinarizer() \n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    pred = lb.transform(pred)\n",
        "    return roc_auc_score(y_test, pred, average=average)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ehP7LEGn7QU",
        "colab_type": "text"
      },
      "source": [
        "# **Fit SnapBoost model to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYCfKz_7lKoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " max_depth = 6\n",
        "num_round = 100\n",
        "learning_rate = 0.1\n",
        "use_gpu = False\n",
        "num_threads = 16\n",
        "booster = BoostingMachine(objective='logloss', num_round=num_round, min_max_depth=max_depth, max_max_depth=max_depth,\n",
        "                             learning_rate=learning_rate, random_state=42, use_gpu=use_gpu, n_threads=num_threads)\n",
        "t1=datetime.now()\n",
        "booster.fit(train_x.to_numpy(), train_y.to_numpy())\n",
        "t2=datetime.now()\n",
        "execution_time_snap_boost = t2-t1\n",
        "t3 = datetime.now()\n",
        "ypred = booster.predict(test_x.to_numpy())\n",
        "t4 = datetime.now()\n",
        "accuracy_snap_boost = round(roc_auc_score(test_y,ypred),2)\n",
        "print(\"Accuracy score = \",accuracy_snap_boost*100,\"%\")\n",
        "print(\"Execution time = \",execution_time_snap_boost)\n",
        "print(\"Prediction time = \",t4-t3)\n",
        "snap_boost_train_time = t2-t1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME1G-KHwoKJM",
        "colab_type": "text"
      },
      "source": [
        "# **Fit LightGBM model to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFiGeOJo1y2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'num_leaves':150, 'objective':'binary','max_depth':7,'learning_rate':.05,'max_bin':200}\n",
        "params['metric'] = ['auc', 'binary_logloss']\n",
        "\n",
        "train_data=lgb.Dataset(X_train,label=y_train)\n",
        "\n",
        "num_round=50\n",
        "t1=datetime.now()\n",
        "lgbm=lgb.train(params,train_data,num_round)\n",
        "t2=datetime.now()\n",
        "execution_time_lgbm = t2-t1\n",
        "t3 = datetime.now()\n",
        "ypred2=lgbm.predict(X_test)\n",
        "t4 = datetime.now()\n",
        "\n",
        "for i in range(0,len(ypred2)): \n",
        "    if ypred2[i] >=0.5:\n",
        "        ypred2[i] = 1\n",
        "    else:\n",
        "        ypred2[i] = 0\n",
        "accuracy_lgbm = round(accuracy_score(ypred2,y_test),5)\n",
        "print(\"Accuracy score = \",accuracy_lgbm*100,\"%\")\n",
        "print(\"Execution time = \",execution_time_lgbm)\n",
        "print(\"Prediction time = \",t4-t3)\n",
        "lgbm_train_time = t2-t1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqeS5jdroSWj",
        "colab_type": "text"
      },
      "source": [
        "# **Fit XGBoost model to the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-TG1-CH2CIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "t1=datetime.now()\n",
        "model.fit(X_train,y_train)\n",
        "t2=datetime.now()\n",
        "execution_time_xgb = t2-t1\n",
        "t3 = datetime.now()\n",
        "y_pred = model.predict(X_test)\n",
        "t4 = datetime.now()\n",
        "predictions = [round(value) for value in y_pred]\n",
        "accuracy_xgb = round(accuracy_score(y_pred,y_test),5)\n",
        "print(\"Accuracy score = \",accuracy_xgb*100,\"%\")\n",
        "print(\"Execution time = \",execution_time_xgb)\n",
        "print(\"Prediction time = \",t4-t3)\n",
        "xgb_train_time = t2-t1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMBDliFocrc",
        "colab_type": "text"
      },
      "source": [
        "# **Results and Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ell_kkAlnfqL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# **1.Accuracy Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhH9vbUf5QFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (4,5))\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "algorithms = ['LightGBM','XGBoost','SnapBoost']\n",
        "accuracy = [accuracy_lgbm*100, accuracy_xgb*100,accuracy_snap_boost*100]\n",
        "g = ax.bar(algorithms,accuracy)\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Algorithms on the Numeric Dataset\")\n",
        "plt.ylabel(\"Accuracy in %\")\n",
        "bar_label = [accuracy_lgbm*100, accuracy_xgb*100,accuracy_snap_boost*100]\n",
        "def autolabel(rects):\n",
        "    for idx,rect in enumerate(g):\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width()/2., 1.0*height,\n",
        "                bar_label[idx],\n",
        "                ha='center', va='bottom', rotation=0)\n",
        "\n",
        "autolabel(g)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZIbPKzlnZOF",
        "colab_type": "text"
      },
      "source": [
        "# **2.Training Time Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx343xBx4xnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lg = float(str(lgbm_train_time)[5:])\n",
        "sb = float(str(snap_boost_train_time)[5:])\n",
        "xgb = float(str(xgb_train_time)[5:])\n",
        "fig1 = plt.figure(figsize = (4,5))\n",
        "ay = fig1.add_axes([0,0,1,1])\n",
        "algorithms = ['LightGBM','XGBoost','SnapBoost']\n",
        "training_time = [lg,xgb,sb]\n",
        "g1 = ay.bar(algorithms,training_time)\n",
        "plt.title(\"Training Time Plot\")\n",
        "plt.xlabel(\"Algorithms on the Numeric Dataset\")\n",
        "plt.ylabel(\"Time Taken in Seconds\")\n",
        "bar_label = training_time\n",
        "def autolabel1(rects):\n",
        "    for idx,rect in enumerate(g1):\n",
        "        height = rect.get_height()\n",
        "        ay.text(rect.get_x() + rect.get_width()/2., 1.0*height,\n",
        "                bar_label[idx],\n",
        "                ha='center', va='bottom', rotation=0)\n",
        "\n",
        "autolabel1(g1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}